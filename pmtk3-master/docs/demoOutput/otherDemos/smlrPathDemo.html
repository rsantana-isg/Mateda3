
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>smlrPathDemo</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-03-27"><meta name="DC.source" content="smlrPathDemo.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">Compare SMLR selecting lambda on grid or on path.</a></li><li><a href="#2">Data</a></li><li><a href="#3">Models</a></li><li><a href="#4">Main</a></li></ul></div><h2>Compare SMLR selecting lambda on grid or on path.<a name="1"></a></h2><p>If  path, we use the same kernel basis for all lambda If grid, we change the basis depending on the fold.</p><p>See also linearKernelDemo</p><pre class="codeinput"><span class="comment">% This file is from pmtk3.googlecode.com</span>

<span class="comment">%PMTKslow</span>

<span class="comment">% Results: rows  = soy, colon</span>
<span class="comment">% cols = 'smlrPath', 'smlrNoPath', 'rmlrPath', 'rmlrNoPath'</span>
<span class="comment">%{
</span><span class="comment">testErrRate =
</span><span class="comment">    0.2366    0.0860    0.0860    0.0323
</span><span class="comment">    0.5789    0.3158    0.3158    0.2105
</span><span class="comment">
</span><span class="comment">trainingTime =
</span><span class="comment">    3.1635   45.5373    0.0000   25.3579
</span><span class="comment">    0.6405    2.5856    0.0000    3.0739
</span><span class="comment">%}
</span>
clear <span class="string">all</span>
setSeed(0);
</pre><h2>Data<a name="2"></a></h2><pre class="codeinput">split = 0.7;
d = 1;

<span class="keyword">if</span> 1
loadData(<span class="string">'soy'</span>) <span class="comment">% 3 classes, X is 307*35</span>
dataSets(d).X = X;
dataSets(d).y = Y;
dataSets(d).name = <span class="string">'soy'</span>;
d=d+1;
<span class="keyword">end</span>

<span class="keyword">if</span> 0
loadData(<span class="string">'fglass'</span>); <span class="comment">% 6 classes, X is 214*9</span>
X = [Xtrain; Xtest];
y = canonizeLabels([ytrain; ytest]); <span class="comment">% class 4 is missing, so relabel 1:6</span>
dataSets(d).X = X;
dataSets(d).y = y;
dataSets(d).name = <span class="string">'fglass'</span>;
d=d+1;
<span class="keyword">end</span>

<span class="keyword">if</span> 1
loadData(<span class="string">'colon'</span>) <span class="comment">% 2 class, X is 62*2000</span>
dataSets(d).X = X;
dataSets(d).y = y;
dataSets(d).name = <span class="string">'colon'</span>;
d=d+1;
<span class="keyword">end</span>

<span class="keyword">if</span> 0
loadData(<span class="string">'amlAll'</span>); <span class="comment">% 2 class, X is 72*7129</span>
X = [Xtrain; Xtest];
y = [ytrain; ytest];
dataSets(d).X = X;
dataSets(d).y = y;
dataSets(d).name = <span class="string">'amlAll'</span>;
d=d+1;
<span class="keyword">end</span>

dataNames = {dataSets.name};
nDataSets = numel(dataSets);
</pre><h2>Models<a name="3"></a></h2><pre class="codeinput">methods = {<span class="string">'smlrPath'</span>, <span class="string">'smlrNoPath'</span>, <span class="string">'rmlrPath'</span>, <span class="string">'rmlrNoPath'</span>};
<span class="keyword">if</span> ~glmnetInstalled
  methods = setdiff(methods, <span class="string">'smlrPath'</span>);
  methods = setdiff(methods, <span class="string">'rmlrPath'</span>);
<span class="keyword">end</span>

nMethods = numel(methods);
</pre><h2>Main<a name="4"></a></h2><pre class="codeinput"><span class="keyword">for</span> d=1:nDataSets
  setSeed(0);
  X = dataSets(d).X;
  y = dataSets(d).y;
  [X, y] = shuffleRows(X, y);
  X      = rescaleData(standardizeCols(X));
  N      = size(X, 1);
  nTrain = floor(split*N);
  nTest  = N - nTrain;
  Xtrain = X(1:nTrain, :);
  Xtest  = X(nTrain+1:end, :);
  ytrain = y(1:nTrain);
  ytest  = y(nTrain+1:end);

  <span class="keyword">for</span> m=1:nMethods
    method = methods{m};
    tic;

    <span class="keyword">switch</span> lower(method)
      <span class="keyword">case</span> <span class="string">'svm'</span>
        <span class="comment">% SVMpath functionality not yet implemented</span>
        <span class="comment">% so internally we do CV over C</span>
        Crange = logspace(-5, 5, 10);
        model = svmFit(Xtrain, ytrain, <span class="string">'C'</span>, Crange,  <span class="string">'kernel'</span>, <span class="string">'linear'</span>);
        predFn = @(m,X) svmPredict(m,X);
      <span class="keyword">case</span> <span class="string">'rvm'</span>
        model = rvmFit(Xtrain, ytrain, [], <span class="string">'kernelFn'</span>, @kernelLinear);
        predFn = @(m,X) rvmPredict(m,X);
      <span class="keyword">case</span> <span class="string">'smlrpath'</span>
        model = smlrFit(Xtrain, ytrain, <span class="string">'kernelFn'</span>, @kernelLinear, <span class="keyword">...</span>
          <span class="string">'usePath'</span>, true);
        predFn = @(m,X) smlrPredict(m,X);
      <span class="keyword">case</span> {<span class="string">'smlrnopath'</span>, <span class="string">'smlr'</span>}
        model = smlrFit(Xtrain, ytrain,  <span class="string">'kernelFn'</span>, @kernelLinear, <span class="keyword">...</span>
          <span class="string">'usePath'</span>, false);
        predFn = @(m,X) smlrPredict(m,X);
      <span class="keyword">case</span> <span class="string">'rmlrpath'</span>
        model = smlrFit(Xtrain, ytrain, <span class="string">'kernelFn'</span>, @kernelLinear, <span class="keyword">...</span>
          <span class="string">'regtype'</span>, <span class="string">'L2'</span>, <span class="string">'usePath'</span>, true);
        predFn = @(m,X) smlrPredict(m,X);
      <span class="keyword">case</span> {<span class="string">'rmlrnopath'</span>, <span class="string">'rmlr'</span>}
        model = smlrFit(Xtrain, ytrain, <span class="string">'kernelFn'</span>, @kernelLinear, <span class="keyword">...</span>
          <span class="string">'regtype'</span>, <span class="string">'L2'</span>, <span class="string">'usePath'</span>, false);
        predFn = @(m,X) smlrPredict(m,X);
      <span class="keyword">case</span> <span class="string">'logregl2'</span>
        model = logregFitPathCv(Xtrain, ytrain, <span class="string">'regtype'</span>, <span class="string">'L2'</span>);
        predFn = @(m,X) logregPredict(m,X);
      <span class="keyword">case</span> <span class="string">'logregl1'</span>
        model = logregFitPathCv(Xtrain, ytrain, <span class="string">'regtype'</span>, <span class="string">'L1'</span>);
        predFn = @(m,X) logregPredict(m,X);
    <span class="keyword">end</span>
    trainingTime(d,m) = toc;
    saveModel{d,m} = model;

    tic
    yHat   = predFn(model, Xtest);
    testingTime(d,m) = toc;

    nerrs  = sum(yHat ~= ytest);
    testErrRate(d,m) = nerrs/nTest;

  <span class="keyword">end</span>
<span class="keyword">end</span>

 testErrRate

 trainingTime
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
%% Compare SMLR selecting lambda on grid or on path.
% If  path, we use the same kernel basis for all lambda
% If grid, we change the basis depending on the fold.
%
% See also linearKernelDemo

% This file is from pmtk3.googlecode.com

%PMTKslow

% Results: rows  = soy, colon
% cols = 'smlrPath', 'smlrNoPath', 'rmlrPath', 'rmlrNoPath'
%{
testErrRate =
    0.2366    0.0860    0.0860    0.0323
    0.5789    0.3158    0.3158    0.2105

trainingTime =
    3.1635   45.5373    0.0000   25.3579
    0.6405    2.5856    0.0000    3.0739
%}
    
clear all
setSeed(0);

%% Data
split = 0.7;
d = 1;

if 1
loadData('soy') % 3 classes, X is 307*35
dataSets(d).X = X; 
dataSets(d).y = Y; 
dataSets(d).name = 'soy';
d=d+1;
end

if 0
loadData('fglass'); % 6 classes, X is 214*9
X = [Xtrain; Xtest];
y = canonizeLabels([ytrain; ytest]); % class 4 is missing, so relabel 1:6
dataSets(d).X = X; 
dataSets(d).y = y; 
dataSets(d).name = 'fglass';
d=d+1;
end

if 1
loadData('colon') % 2 class, X is 62*2000
dataSets(d).X = X;
dataSets(d).y = y;
dataSets(d).name = 'colon';
d=d+1;
end

if 0
loadData('amlAll'); % 2 class, X is 72*7129
X = [Xtrain; Xtest];
y = [ytrain; ytest]; 
dataSets(d).X = X;
dataSets(d).y = y;
dataSets(d).name = 'amlAll';
d=d+1;
end

dataNames = {dataSets.name};
nDataSets = numel(dataSets);


%% Models
methods = {'smlrPath', 'smlrNoPath', 'rmlrPath', 'rmlrNoPath'};
if ~glmnetInstalled
  methods = setdiff(methods, 'smlrPath');
  methods = setdiff(methods, 'rmlrPath');
end

nMethods = numel(methods);

%% Main
for d=1:nDataSets
  setSeed(0);
  X = dataSets(d).X;
  y = dataSets(d).y;
  [X, y] = shuffleRows(X, y);
  X      = rescaleData(standardizeCols(X));
  N      = size(X, 1);
  nTrain = floor(split*N);
  nTest  = N - nTrain;
  Xtrain = X(1:nTrain, :);
  Xtest  = X(nTrain+1:end, :);
  ytrain = y(1:nTrain);
  ytest  = y(nTrain+1:end);
  
  for m=1:nMethods
    method = methods{m};
    tic;
    
    switch lower(method)
      case 'svm'
        % SVMpath functionality not yet implemented
        % so internally we do CV over C
        Crange = logspace(-5, 5, 10);
        model = svmFit(Xtrain, ytrain, 'C', Crange,  'kernel', 'linear');
        predFn = @(m,X) svmPredict(m,X);
      case 'rvm'
        model = rvmFit(Xtrain, ytrain, [], 'kernelFn', @kernelLinear);
        predFn = @(m,X) rvmPredict(m,X);
      case 'smlrpath'
        model = smlrFit(Xtrain, ytrain, 'kernelFn', @kernelLinear, ...
          'usePath', true);
        predFn = @(m,X) smlrPredict(m,X);
      case {'smlrnopath', 'smlr'}
        model = smlrFit(Xtrain, ytrain,  'kernelFn', @kernelLinear, ...
          'usePath', false);
        predFn = @(m,X) smlrPredict(m,X);
      case 'rmlrpath'
        model = smlrFit(Xtrain, ytrain, 'kernelFn', @kernelLinear, ...
          'regtype', 'L2', 'usePath', true);
        predFn = @(m,X) smlrPredict(m,X);
      case {'rmlrnopath', 'rmlr'}
        model = smlrFit(Xtrain, ytrain, 'kernelFn', @kernelLinear, ...
          'regtype', 'L2', 'usePath', false);
        predFn = @(m,X) smlrPredict(m,X);
      case 'logregl2'
        model = logregFitPathCv(Xtrain, ytrain, 'regtype', 'L2');
        predFn = @(m,X) logregPredict(m,X);
      case 'logregl1'
        model = logregFitPathCv(Xtrain, ytrain, 'regtype', 'L1');
        predFn = @(m,X) logregPredict(m,X);
    end
    trainingTime(d,m) = toc;
    saveModel{d,m} = model;
    
    tic
    yHat   = predFn(model, Xtest);
    testingTime(d,m) = toc;
    
    nerrs  = sum(yHat ~= ytest);
    testErrRate(d,m) = nerrs/nTest;
    
  end
end

 testErrRate
 
 trainingTime
 
 

##### SOURCE END #####
--></body></html>