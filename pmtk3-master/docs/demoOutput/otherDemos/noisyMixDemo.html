
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>noisyMixDemo</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-03-27"><meta name="DC.source" content="noisyMixDemo.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><pre class="codeinput"><span class="comment">% Z -&gt; Xj -&gt; Yj</span>
<span class="comment">% Z is mixture node</span>
<span class="comment">% Xj is binary tag</span>
<span class="comment">% Yj is response of tag detector</span>

<span class="comment">% We generate some synthetic correlated binary data</span>
<span class="comment">% consisting of 10s and 01s</span>

setSeed(0);
D = 4; <span class="comment">% num bits/ nodes</span>
mixWeights = normalize(ones(1,D));
N2 = 20;
X1 = repmat([1 0 0 1], N2, 1);
X2 = repmat([0 1 1 0], N2, 1);
X = [X1; X2];
X = X+1;
N  = 2*N2;

options = {<span class="string">'maxIter'</span>, 10, <span class="string">'verbose'</span>, true};
K = 2;
[model, loglikHist] = mixDiscreteFit(X, K, options{:});

<span class="comment">%{
</span><span class="comment">This works as expected: in cluster 1,
</span><span class="comment">the first feature (col 1) is most likely 1,
</span><span class="comment">the second feature (col 2) is most likely 0
</span><span class="comment">etc
</span><span class="comment">
</span><span class="comment">&gt; squeeze(model.cpd.T(1,:,:)) % soft version of 0 1 1 0 pattern
</span><span class="comment">ans =
</span><span class="comment">    0.0455    0.9545    0.9545    0.0455
</span><span class="comment">    0.9545    0.0455    0.0455    0.9545
</span><span class="comment">
</span><span class="comment">
</span><span class="comment">
</span><span class="comment">and vice versa for cluster 2
</span><span class="comment">
</span><span class="comment">squeeze(model.cpd.T(2,:,:))  % soft version of 1 0 0 1 pattern
</span><span class="comment">ans =
</span><span class="comment">    0.9545    0.0455    0.0455    0.9545
</span><span class="comment">    0.0455    0.9545    0.9545    0.0455
</span><span class="comment">
</span><span class="comment">%}
</span>
<span class="comment">% Now generate noisy function of X</span>

setSeed(0);

<span class="comment">% mu(c,j)</span>
<span class="comment">% Make off bits be -ve, on bits be +ve</span>
mu = [-1 -2 -3 -4;
       1  2  3  4];

sigma = 2;
Y = zeros(N, D);

<span class="keyword">for</span> j=1:D
  <span class="keyword">for</span> c=1:2
    ndx = find(X(:,j)==c);
    Y(ndx,j) = sigma*randn(numel(ndx),1)+mu(c,j);
  <span class="keyword">end</span>
<span class="keyword">end</span>

[model2] = noisyMixModelFit(X, Y, K);

<span class="comment">%{
</span><span class="comment">Mix model Z-&gt;X is same as before (modulo label switching)
</span><span class="comment">
</span><span class="comment">squeeze(model2.mixmodel.cpd.T(1,:,:))  % soft version of 1 0 0 1 pattern
</span><span class="comment">
</span><span class="comment">squeeze(model2.mixmodel.cpd.T(2,:,:))  % soft version of 0 1 1 0 pattern
</span><span class="comment">
</span><span class="comment">
</span><span class="comment">Obs model
</span><span class="comment">
</span><span class="comment">for j=1:D
</span><span class="comment">mu2(:,j) = model2.obsmodel.localCPDs{j}.mu';
</span><span class="comment">end
</span><span class="comment">
</span><span class="comment">
</span><span class="comment">mu2 =
</span><span class="comment">   -0.8839   -2.1571   -2.9969   -4.0548
</span><span class="comment">    1.1921    2.0855    2.5789    3.8201
</span><span class="comment">
</span><span class="comment">%}
</span>
<span class="comment">% "batch" inference</span>
[pZ, pX] = noisyMixModelInfer(model2, Y);

<span class="comment">%{
</span><span class="comment">% sequential inference
</span><span class="comment">pZ2 = zeros(size(pZ));
</span><span class="comment">pX2 = zeros(size(pX));
</span><span class="comment">for i=1:N
</span><span class="comment">  [pZ2(i,:), pX2(i,:,:)] = noisyMixModelInfer(model2, Y(i,:));
</span><span class="comment">end
</span><span class="comment">assert(approxeq(pZ, pZ2))
</span><span class="comment">assert(approxeq(pX, pX2))
</span><span class="comment">%}
</span>
<span class="comment">% Check that each row assigned to 'correct' cluster</span>
[pmax, Zhat] = max(pZ,[],2);
<span class="comment">% Zhat(1:20) = 1 for 1st cluster</span>
<span class="comment">% Zhat(21:40) = 2</span>

figure; imagesc(Y); colorbar; title(<span class="string">'raw data Y (score of detector)'</span>);
figure; imagesc(pZ); colorbar; title(<span class="string">'soft clustering pZ'</span>)

<span class="comment">% Now check that we infered correct tag, marginalizing out cluster</span>
Xhat = zeros(N, D);
<span class="keyword">for</span> j=1:D
  [pmax, Xhat(:, j)] = max(pX(:, :, j), [], 2); <span class="comment">% pX is N*2*D</span>
<span class="keyword">end</span>
<span class="comment">% Xhat recovers X</span>
figure; imagesc(X); colorbar; title(<span class="string">'true tag'</span>);
figure; imagesc(Xhat); colorbar; title(<span class="string">'est tag'</span>);
</pre><pre class="codeoutput">initializing model for EM
1	 loglik: -112.753
2	 loglik: -97.4307
3	 loglik: -48.0588
4	 loglik: -34.1614
5	 loglik: -34.1568
6	 loglik: -34.1568
initializing model for EM
1	 loglik: -111.634
2	 loglik: -95.9039
3	 loglik: -44.8179
4	 loglik: -29.1651
5	 loglik: -29.1122
6	 loglik: -29.1122
</pre><img vspace="5" hspace="5" src="noisyMixDemo_01.png" alt=""> <img vspace="5" hspace="5" src="noisyMixDemo_02.png" alt=""> <img vspace="5" hspace="5" src="noisyMixDemo_03.png" alt=""> <img vspace="5" hspace="5" src="noisyMixDemo_04.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####

% Z -> Xj -> Yj
% Z is mixture node
% Xj is binary tag
% Yj is response of tag detector

% We generate some synthetic correlated binary data
% consisting of 10s and 01s

setSeed(0);
D = 4; % num bits/ nodes
mixWeights = normalize(ones(1,D));
N2 = 20;
X1 = repmat([1 0 0 1], N2, 1);
X2 = repmat([0 1 1 0], N2, 1);
X = [X1; X2];
X = X+1; 
N  = 2*N2;

options = {'maxIter', 10, 'verbose', true};
K = 2;
[model, loglikHist] = mixDiscreteFit(X, K, options{:});

%{
This works as expected: in cluster 1,
the first feature (col 1) is most likely 1,
the second feature (col 2) is most likely 0
etc

> squeeze(model.cpd.T(1,:,:)) % soft version of 0 1 1 0 pattern
ans =
    0.0455    0.9545    0.9545    0.0455
    0.9545    0.0455    0.0455    0.9545



and vice versa for cluster 2

squeeze(model.cpd.T(2,:,:))  % soft version of 1 0 0 1 pattern
ans =
    0.9545    0.0455    0.0455    0.9545
    0.0455    0.9545    0.9545    0.0455

%}

% Now generate noisy function of X

setSeed(0);

% mu(c,j) 
% Make off bits be -ve, on bits be +ve
mu = [-1 -2 -3 -4;
       1  2  3  4];
     
sigma = 2;
Y = zeros(N, D);

for j=1:D
  for c=1:2
    ndx = find(X(:,j)==c);
    Y(ndx,j) = sigma*randn(numel(ndx),1)+mu(c,j);
  end
end

[model2] = noisyMixModelFit(X, Y, K);

%{
Mix model Z->X is same as before (modulo label switching)

squeeze(model2.mixmodel.cpd.T(1,:,:))  % soft version of 1 0 0 1 pattern

squeeze(model2.mixmodel.cpd.T(2,:,:))  % soft version of 0 1 1 0 pattern


Obs model

for j=1:D
mu2(:,j) = model2.obsmodel.localCPDs{j}.mu';
end


mu2 =
   -0.8839   -2.1571   -2.9969   -4.0548
    1.1921    2.0855    2.5789    3.8201

%}

% "batch" inference
[pZ, pX] = noisyMixModelInfer(model2, Y);

%{
% sequential inference
pZ2 = zeros(size(pZ));
pX2 = zeros(size(pX));
for i=1:N
  [pZ2(i,:), pX2(i,:,:)] = noisyMixModelInfer(model2, Y(i,:));
end
assert(approxeq(pZ, pZ2))
assert(approxeq(pX, pX2))
%}

% Check that each row assigned to 'correct' cluster
[pmax, Zhat] = max(pZ,[],2);
% Zhat(1:20) = 1 for 1st cluster
% Zhat(21:40) = 2

figure; imagesc(Y); colorbar; title('raw data Y (score of detector)');
figure; imagesc(pZ); colorbar; title('soft clustering pZ')

% Now check that we infered correct tag, marginalizing out cluster
Xhat = zeros(N, D);
for j=1:D
  [pmax, Xhat(:, j)] = max(pX(:, :, j), [], 2); % pX is N*2*D
end
% Xhat recovers X
figure; imagesc(X); colorbar; title('true tag');
figure; imagesc(Xhat); colorbar; title('est tag');


##### SOURCE END #####
--></body></html>