
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Bayes factors for simple linear regression</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-03-27"><meta name="DC.source" content="linregBFCaterpillar.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Bayes factors for simple linear regression</h1><!--introduction--><p>We reproduce the example on p64 of Marin and Robert, 2007 This computes logBF(i) = log p(D|X(:,:)) / p(D|X(:,-j)) for each feature j using a g-prior</p><!--/introduction--><pre class="codeinput"><span class="comment">% This file is from pmtk3.googlecode.com</span>

X = loadData(<span class="string">'caterpillar'</span>);
<span class="comment">% from http://www.ceremade.dauphine.fr/~xian/BCS/caterpillar</span>
y = log(X(:,11)); <span class="comment">% log number of nests</span>
X = X(:,1:10);
[n,d] = size(X);
X1 = [ones(n,1), X];

g = 100;
what = X1\y; <span class="comment">% MLE</span>
mu = g/(g+1)*what; <span class="comment">% post mean, eqn 3.7</span>
yhat = X1*what;
s2 = (y-yhat)'*(y-yhat);
v = s2 + what'*X1'*X1*what/(g+1); <span class="comment">% eqn below 3.8</span>
Sigma = g/(g+1)*v/n*inv(X1'*X1);
vvar = diag(Sigma);


<span class="comment">% unnormalized log p(data|Model i)</span>
<span class="keyword">for</span> i=1:(d+1)
   X1i =  X1; X1i(:,i) = []; <span class="comment">% X1(:,models{i});</span>
   q = 1; <span class="comment">% num coeffs which are set to 0</span>
   logprob(i) = -(d+1-q)/2 * log10(g+1) + <span class="keyword">...</span>
      -(n/2)*log10(y'*y - (g/(g+1))*y'*X1i*inv(X1i'*X1i)*X1i'*y);
<span class="keyword">end</span>
logprobFull = -(d+1)/2 * log10(g+1) + <span class="keyword">...</span>
      -(n/2)*log10(y'*y - (g/(g+1))*y'*X1*inv(X1'*X1)*X1'*y);
logBF = logprobFull  - logprob;
BF = 10.^logBF;

<span class="keyword">for</span> i=1:(d+1)
   <span class="comment">% jeffreys scale of evidence, "The bayesian choice", 2e, p228</span>
   <span class="keyword">if</span> BF(i)&gt;100
      sym = <span class="string">'(****)'</span>; <span class="comment">% decisive</span>
   <span class="keyword">elseif</span> BF(i)&gt;10
      sym = <span class="string">'(***)'</span>; <span class="comment">% strong</span>
   <span class="keyword">elseif</span> BF(i) &gt; 3 <span class="comment">% moderate</span>
      sym = <span class="string">'(**)'</span>;
   <span class="keyword">elseif</span> BF(i) &gt; 1 <span class="comment">% weak</span>
      sym = <span class="string">'(*)'</span>;
   <span class="keyword">else</span>
      sym = <span class="string">''</span>;
   <span class="keyword">end</span>
   fprintf(<span class="string">'w%d &amp; %5.3f &amp; %5.3f &amp; %5.3f  %s\\\\\n'</span>, <span class="keyword">...</span>
      i-1, mu(i), sqrt(vvar(i)), logBF(i), sym);
<span class="keyword">end</span>
</pre><pre class="codeoutput">w0 &amp; 10.890 &amp; 2.532 &amp; 2.187  (****)\\
w1 &amp; -0.004 &amp; 0.001 &amp; 1.157  (***)\\
w2 &amp; -0.053 &amp; 0.018 &amp; 0.667  (**)\\
w3 &amp; 0.067 &amp; 0.082 &amp; -0.859  \\
w4 &amp; -1.281 &amp; 0.466 &amp; 0.473  (*)\\
w5 &amp; 0.229 &amp; 0.086 &amp; 0.386  (*)\\
w6 &amp; -0.353 &amp; 1.296 &amp; -0.986  \\
w7 &amp; -0.235 &amp; 0.832 &amp; -0.985  \\
w8 &amp; 0.179 &amp; 0.196 &amp; -0.822  \\
w9 &amp; -1.273 &amp; 0.715 &amp; -0.346  \\
w10 &amp; -0.429 &amp; 0.608 &amp; -0.895  \\
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
%% Bayes factors for simple linear regression
% We reproduce the example on p64 of Marin and Robert, 2007
% This computes logBF(i) = log p(D|X(:,:)) / p(D|X(:,-j)) for each feature j 
% using a g-prior
%%

% This file is from pmtk3.googlecode.com

X = loadData('caterpillar');
% from http://www.ceremade.dauphine.fr/~xian/BCS/caterpillar
y = log(X(:,11)); % log number of nests
X = X(:,1:10);
[n,d] = size(X);
X1 = [ones(n,1), X];

g = 100;
what = X1\y; % MLE
mu = g/(g+1)*what; % post mean, eqn 3.7
yhat = X1*what;
s2 = (y-yhat)'*(y-yhat);
v = s2 + what'*X1'*X1*what/(g+1); % eqn below 3.8
Sigma = g/(g+1)*v/n*inv(X1'*X1);
vvar = diag(Sigma);


% unnormalized log p(data|Model i)
for i=1:(d+1)
   X1i =  X1; X1i(:,i) = []; % X1(:,models{i});
   q = 1; % num coeffs which are set to 0
   logprob(i) = -(d+1-q)/2 * log10(g+1) + ...
      -(n/2)*log10(y'*y - (g/(g+1))*y'*X1i*inv(X1i'*X1i)*X1i'*y);
end
logprobFull = -(d+1)/2 * log10(g+1) + ...
      -(n/2)*log10(y'*y - (g/(g+1))*y'*X1*inv(X1'*X1)*X1'*y);
logBF = logprobFull  - logprob;
BF = 10.^logBF;

for i=1:(d+1)
   % jeffreys scale of evidence, "The bayesian choice", 2e, p228
   if BF(i)>100
      sym = '(****)'; % decisive
   elseif BF(i)>10
      sym = '(***)'; % strong
   elseif BF(i) > 3 % moderate
      sym = '(**)';
   elseif BF(i) > 1 % weak
      sym = '(*)';
   else
      sym = '';
   end
   fprintf('w%d & %5.3f & %5.3f & %5.3f  %s\\\\\n', ...
      i-1, mu(i), sqrt(vvar(i)), logBF(i), sym);
end



##### SOURCE END #####
--></body></html>