
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>gpSpatialDemoLaplace</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-03-27"><meta name="DC.source" content="gpSpatialDemoLaplace.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><pre class="codeinput"><span class="comment">%PMTKauthor Jarno Vanhatalo</span>
<span class="comment">% Same as demo_spatial1 from GPstuff-2.0 except</span>
<span class="comment">% we only run Laplace, not MCMC, for speed</span>

<span class="comment">%DEMO_SPATIAL1    Demonstration for a disease mapping problem</span>
<span class="comment">%                 with Gaussian process prior and Poisson likelihood</span>
<span class="comment">%</span>
<span class="comment">%    Description</span>

<span class="comment">%    The disease mapping problem consist of a data with number of</span>
<span class="comment">%    death cases, Y, and background population, N, appointed to</span>
<span class="comment">%    co-ordinates, X.  The goal is to find a relative risk surface,</span>
<span class="comment">%    which describes if the number of death cases in certain areas is</span>
<span class="comment">%    lower or higher than expected.  The data consists of the heart</span>
<span class="comment">%    attacks in Finland from 1996-2000 aggregated into 20kmx20km</span>
<span class="comment">%    lattice cells.</span>
<span class="comment">%</span>
<span class="comment">%    The model constructed is as follows:</span>
<span class="comment">%</span>
<span class="comment">%    The number of death cases Y_i in area i is assumed to satisfy</span>
<span class="comment">%</span>
<span class="comment">%         Y_i ~ Poisson(Y_i| E_i * r_i)</span>
<span class="comment">%</span>
<span class="comment">%    where E_i is the expected number of deaths (see Vanhatalo and</span>
<span class="comment">%    Vehtari (2007, 2010), how E_i is evaluated) at area i and r_i is</span>
<span class="comment">%    the relative risk.</span>
<span class="comment">%</span>
<span class="comment">%    We place a zero mean Gaussian process prior for log(R), R = [r_1,</span>
<span class="comment">%    r_2,...,r_n], which implies that at the observed input locations</span>
<span class="comment">%    latent values, f, have prior</span>
<span class="comment">%</span>
<span class="comment">%         f = log(R) ~ N(0, K),</span>
<span class="comment">%</span>
<span class="comment">%    where K is the covariance matrix, whose elements are given as</span>
<span class="comment">%    K_ij = k(x_i, x_j | th). The function k(x_i, x_j | th) is</span>
<span class="comment">%    covariance function and th its parameters, hyperparameters.  We</span>
<span class="comment">%    place a hyperprior for hyperparameters, p(th).</span>
<span class="comment">%</span>
<span class="comment">%    Since the data set used in this demo is rather large we use FIC</span>
<span class="comment">%    sparse approximation for the GP prior.</span>
<span class="comment">%</span>
<span class="comment">%    The inference is conducted first with Laplace approximation and</span>
<span class="comment">%    then via MCMC. We sample from the full posterior p(f, th| data)</span>
<span class="comment">%    by alternating the sampling from the conditional posteriors p(f |</span>
<span class="comment">%    th, data) and p(th | f, data). The sampling from the conditional</span>
<span class="comment">%    posteriors is done by hybrid Monte Carlo (see, for example, Neal,</span>
<span class="comment">%    1996).</span>
<span class="comment">%</span>
<span class="comment">%    See Vanhatalo and Vehtari (2007) and Vanhatalo et.al. (2010) for</span>
<span class="comment">%    more detailed discussion.</span>
<span class="comment">%</span>
<span class="comment">%    This demo is organised in three parts:</span>
<span class="comment">%     1) data analysis with Laplace approximation</span>
<span class="comment">%     2) data analysis with integrated Laplace approximation</span>
<span class="comment">%     3) data analysis with MCMC</span>
<span class="comment">%</span>
<span class="comment">%    See also  DEMO_REGRESSION1, DEMO_CLASSIFIC1</span>
<span class="comment">%</span>
<span class="comment">%</span>
<span class="comment">%   Refernces:</span>
<span class="comment">%    Vanhatalo, J., Pietil&auml;inen V. and Vehtari, A. (2010). Approximate</span>
<span class="comment">%    inference for disease mapping with sparse Gaussian processes.</span>
<span class="comment">%    Statistics in Medicine, 29(15):.</span>
<span class="comment">%</span>
<span class="comment">%    Jarno Vanhatalo and Aki Vehtari (2007). Sparse Log Gaussian</span>
<span class="comment">%    Processes via MCMC for Spatial Epidemiology. JMLR Workshop and</span>
<span class="comment">%    Conference Proceedings, 1:73-89. (Gaussian Processes in Practice)</span>

<span class="comment">% Copyright (c) 2008-2010 Jarno Vanhatalo</span>

<span class="comment">% This software is distributed under the GNU General Public</span>
<span class="comment">% License (version 2 or later); please refer to the file</span>
<span class="comment">% License.txt, included with the software, for details.</span>


<span class="comment">% =====================================</span>
<span class="comment">% 1) Laplace approximation</span>
<span class="comment">% =====================================</span>

<span class="comment">% load the data</span>
S = which(<span class="string">'demo_spatial1'</span>);
data = load(strrep(S,<span class="string">'demo_spatial1.m'</span>,<span class="string">'demos/spatial1.txt'</span>));

xx = data(:,1:2);
ye = data(:,3);
yy = data(:,4);


<span class="comment">% Now we have loaded the following parameters</span>
<span class="comment">% xx = co-ordinates</span>
<span class="comment">% yy = number of deaths</span>
<span class="comment">% ye = the expexted number of deaths</span>

<span class="comment">% Set the inducing inputs in a regular grid.  Set_PIC returns the</span>
<span class="comment">% induving inputs and blockindeces for PIC. It also plots the data</span>
<span class="comment">% points, inducing inputs and blocks.</span>
dims = [1    60     1    35];
[trindex, Xu] = set_PIC(xx, dims, 5, <span class="string">'corners'</span>, 0);

[n,nin] = size(xx);

<span class="comment">% Create the covariance functions</span>
gpcf1 = gpcf_matern32(<span class="string">'init'</span>, <span class="string">'lengthScale'</span>, 5, <span class="string">'magnSigma2'</span>, 0.05);
pl = prior_t(<span class="string">'init'</span>);
pm = prior_t(<span class="string">'init'</span>, <span class="string">'s2'</span>, 0.3);
gpcf1 = gpcf_matern32(<span class="string">'set'</span>, gpcf1, <span class="string">'lengthScale_prior'</span>, pl, <span class="string">'magnSigma2_prior'</span>, pm);

<span class="comment">% Create the likelihood structure</span>
likelih = likelih_poisson(<span class="string">'init'</span>);

<span class="comment">% Create the FIC GP data structure so that inducing inputs are not optimized</span>
gp = gp_init(<span class="string">'init'</span>, <span class="string">'FIC'</span>, likelih, {gpcf1}, [], <span class="string">'X_u'</span>, Xu, <span class="string">'jitterSigma2'</span>, 0.001);
gp = gp_init(<span class="string">'set'</span>, gp, <span class="string">'infer_params'</span>, <span class="string">'covariance'</span>);

<span class="comment">% --- MAP estimate with Laplace approximation ---</span>

<span class="comment">% Set the approximate inference method to Laplace approximation</span>
gp = gp_init(<span class="string">'set'</span>, gp, <span class="string">'latent_method'</span>, {<span class="string">'Laplace'</span>, xx, yy, <span class="string">'z'</span>, ye});

w=gp_pak(gp);  <span class="comment">% pack the hyperparameters into one vector</span>
fe=str2fun(<span class="string">'gpla_e'</span>);     <span class="comment">% create a function handle to negative log posterior</span>
fg=str2fun(<span class="string">'gpla_g'</span>);     <span class="comment">% create a function handle to gradient of negative log posterior</span>

<span class="comment">% set the options for scg2</span>
opt = scg2_opt;
opt.tolfun = 1e-3;
opt.tolx = 1e-3;
opt.display = 1;

<span class="comment">% do the optimization and set the optimized hyperparameter values back to the gp structure</span>
w=scg2(fe, w, opt, fg, gp, xx, yy, <span class="string">'z'</span>, ye);
gp=gp_unpak(gp,w);

<span class="comment">% make prediction to the data points</span>
[Ef, Varf] = la_pred(gp, xx, yy, xx, <span class="string">'z'</span>, ye, <span class="string">'tstind'</span>, [1:n]);

<span class="comment">% Define help parameters for plotting</span>
xxii=sub2ind([60 35],xx(:,2),xx(:,1));
[X1,X2]=meshgrid(1:35,1:60);

<span class="comment">% Plot the figures</span>
<span class="comment">% In the results it should be noticed that:</span>
<span class="comment">% - there is much more people living in the south than in the north.</span>
<span class="comment">%   This results in rather high variance in the north</span>
<span class="comment">% - The eastern Finland is known to be worse than western Finland in</span>
<span class="comment">%   heart diseases also from other studies.</span>
<span class="comment">% - The inducing inputs are set slightly too sparsely for this data,</span>
<span class="comment">%   which results in oversmoothness in the maps</span>
figure
G=repmat(NaN,size(X1));
G(xxii)=exp(Ef);
pcolor(X1,X2,G),shading <span class="string">flat</span>
colormap(mapcolor(G)),colorbar
<span class="comment">%set(gca, 'Clim', [0.6    1.5])</span>
axis <span class="string">equal</span>
axis([0 35 0 60])
title(<span class="string">'Posterior mean of the relative risk, FIC'</span>)
printPmtkFigure(<span class="string">'gpSpatialDemoLaplaceMean'</span>)


figure
G=repmat(NaN,size(X1));
G(xxii)=(exp(Varf) - 1).*exp(2*Ef+Varf);
pcolor(X1,X2,G),shading <span class="string">flat</span>
colormap(mapcolor(G)),colorbar
<span class="comment">%set(gca, 'Clim', [0.005    0.03])</span>
axis <span class="string">equal</span>
axis([0 35 0 60])
title(<span class="string">'Posterior variance of the relative risk, FIC'</span>)
printPmtkFigure(<span class="string">'gpSpatialDemoLaplaceVar'</span>)



<span class="comment">% the MAP estimate of the hyperparameters in kilometers. Notice that the</span>
<span class="comment">% co-ordinates in the data are not in kilometers. x=1 corresponds to 20km</span>
<span class="comment">% in real life</span>
S2 = sprintf(<span class="string">'lengt-scale: %.3f, magnSigma2: %.3f \n'</span>, gp.cf{1}.lengthScale, gp.cf{1}.magnSigma2)

<span class="comment">%{
</span><span class="comment">% --- MCMC ---
</span><span class="comment">
</span><span class="comment">% Set the approximate inference method to MCMC
</span><span class="comment">gp = gp_init('set', gp, 'latent_method', {'MCMC', zeros(size(yy))', @scaled_hmc});
</span><span class="comment">
</span><span class="comment">% Set the sampling options
</span><span class="comment">
</span><span class="comment">% HMC-hyper
</span><span class="comment">hmc_opt.steps=3;
</span><span class="comment">hmc_opt.stepadj=0.01;
</span><span class="comment">hmc_opt.nsamples=1;
</span><span class="comment">hmc_opt.persistence=0;
</span><span class="comment">hmc_opt.decay=0.8;
</span><span class="comment">
</span><span class="comment">% HMC-latent
</span><span class="comment">latent_opt.nsamples=1;
</span><span class="comment">latent_opt.nomit=0;
</span><span class="comment">latent_opt.persistence=0;
</span><span class="comment">latent_opt.repeat=20;
</span><span class="comment">latent_opt.steps=20;
</span><span class="comment">latent_opt.stepadj=0.15;
</span><span class="comment">latent_opt.window=5;
</span><span class="comment">
</span><span class="comment">% Here we make an initialization with
</span><span class="comment">% slow sampling parameters
</span><span class="comment">[rgp,gp,opt]=gp_mc(gp, xx, yy, 'z', ye, 'hmc_opt', hmc_opt, 'latent_opt', latent_opt);
</span><span class="comment">
</span><span class="comment">% Now we reset the sampling parameters to
</span><span class="comment">% achieve faster sampling
</span><span class="comment">opt.latent_opt.repeat=1;
</span><span class="comment">opt.latent_opt.steps=7;
</span><span class="comment">opt.latent_opt.window=1;
</span><span class="comment">opt.latent_opt.stepadj=0.15;
</span><span class="comment">opt.hmc_opt.persistence=0;
</span><span class="comment">opt.hmc_opt.stepadj=0.01;
</span><span class="comment">opt.hmc_opt.steps=2;
</span><span class="comment">
</span><span class="comment">opt.display = 1;
</span><span class="comment">opt.hmc_opt.display = 0;
</span><span class="comment">opt.latent_opt.display=0;
</span><span class="comment">
</span><span class="comment">% Define help parameters for plotting
</span><span class="comment">xxii=sub2ind([60 35],xx(:,2),xx(:,1));
</span><span class="comment">[X1,X2]=meshgrid(1:35,1:60);
</span><span class="comment">
</span><span class="comment">% Conduct the actual sampling.
</span><span class="comment">% Inside the loop we sample one sample from the latent values and
</span><span class="comment">% hyper-parameters at each iteration. After that we plot the samples
</span><span class="comment">% so that we can visually inspect the progress of sampling
</span><span class="comment">while length(rgp.edata)&lt;1000 %   1000
</span><span class="comment">    [rgp,gp,opt]=gp_mc(gp, xx, yy, 'record', rgp, 'z', ye, opt);
</span><span class="comment">    fprintf('        mean hmcrej: %.2f latrej: %.2f\n', mean(rgp.hmcrejects), mean(rgp.lrejects))
</span><span class="comment">    figure(3)
</span><span class="comment">    clf
</span><span class="comment">    subplot(1,2,1)
</span><span class="comment">    plot(rgp.cf{1}.lengthScale, rgp.cf{1}.magnSigma2)
</span><span class="comment">    xlabel('lenght-scale')
</span><span class="comment">    ylabel('magnitude')
</span><span class="comment">    hold on
</span><span class="comment">    plot(rgp.cf{1}.lengthScale(end), rgp.cf{1}.magnSigma2(end),'r*')
</span><span class="comment">    drawnow
</span><span class="comment">    %    subplot(2,2,[2 4])
</span><span class="comment">    subplot(1,2,2)
</span><span class="comment">    G=repmat(NaN,size(X1));
</span><span class="comment">    G(xxii)=exp(gp.latentValues);
</span><span class="comment">    pcolor(X1,X2,G),shading flat
</span><span class="comment">    colormap(mapcolor(G)),colorbar
</span><span class="comment">    axis equal
</span><span class="comment">    axis([0 35 0 60])
</span><span class="comment">    title('relative risk')
</span><span class="comment">    drawnow
</span><span class="comment">end
</span><span class="comment">
</span><span class="comment">figure(3)
</span><span class="comment">clf
</span><span class="comment">G=repmat(NaN,size(X1));
</span><span class="comment">G(xxii)=median(exp(rgp.latentValues));
</span><span class="comment">pcolor(X1,X2,G),shading flat
</span><span class="comment">colormap(mapcolor(G)),colorbar
</span><span class="comment">set(gca, 'Clim', [0.6    1.5])
</span><span class="comment">axis equal
</span><span class="comment">axis([0 35 0 60])
</span><span class="comment">title('Posterior median of relative risk, FIC GP')
</span><span class="comment">
</span><span class="comment">figure(4)
</span><span class="comment">G=repmat(NaN,size(X1));
</span><span class="comment">G(xxii)=std(exp(rgp.latentValues), [], 1).^2;
</span><span class="comment">pcolor(X1,X2,G),shading flat
</span><span class="comment">colormap(mapcolor(G)),colorbar
</span><span class="comment">set(gca, 'Clim', [0.005    0.03])
</span><span class="comment">axis equal
</span><span class="comment">axis([0 35 0 60])
</span><span class="comment">title('Posterior variance of relative risk, FIC GP')
</span><span class="comment">%}</span>
</pre><pre class="codeoutput">Cycle    1  Error 2697.954880  Scale 1.000000e+00
Cycle    2  Error 2697.656280  Scale 5.000000e-01
Cycle    3  Error 2697.656274  Scale 2.500000e-01
Tolx and tolfun reached
S2 =
lengt-scale: 4.457, magnSigma2: 0.037 

</pre><img vspace="5" hspace="5" src="gpSpatialDemoLaplace_01.png" alt=""> <img vspace="5" hspace="5" src="gpSpatialDemoLaplace_02.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
%PMTKauthor Jarno Vanhatalo
% Same as demo_spatial1 from GPstuff-2.0 except
% we only run Laplace, not MCMC, for speed

%DEMO_SPATIAL1    Demonstration for a disease mapping problem
%                 with Gaussian process prior and Poisson likelihood
%
%    Description

%    The disease mapping problem consist of a data with number of
%    death cases, Y, and background population, N, appointed to
%    co-ordinates, X.  The goal is to find a relative risk surface,
%    which describes if the number of death cases in certain areas is
%    lower or higher than expected.  The data consists of the heart
%    attacks in Finland from 1996-2000 aggregated into 20kmx20km
%    lattice cells.
%
%    The model constructed is as follows:
%
%    The number of death cases Y_i in area i is assumed to satisfy
%
%         Y_i ~ Poisson(Y_i| E_i * r_i)
%
%    where E_i is the expected number of deaths (see Vanhatalo and
%    Vehtari (2007, 2010), how E_i is evaluated) at area i and r_i is
%    the relative risk.
%
%    We place a zero mean Gaussian process prior for log(R), R = [r_1,
%    r_2,...,r_n], which implies that at the observed input locations
%    latent values, f, have prior
%
%         f = log(R) ~ N(0, K),
%
%    where K is the covariance matrix, whose elements are given as
%    K_ij = k(x_i, x_j | th). The function k(x_i, x_j | th) is
%    covariance function and th its parameters, hyperparameters.  We
%    place a hyperprior for hyperparameters, p(th).
%
%    Since the data set used in this demo is rather large we use FIC
%    sparse approximation for the GP prior.
%
%    The inference is conducted first with Laplace approximation and
%    then via MCMC. We sample from the full posterior p(f, th| data)
%    by alternating the sampling from the conditional posteriors p(f |
%    th, data) and p(th | f, data). The sampling from the conditional
%    posteriors is done by hybrid Monte Carlo (see, for example, Neal,
%    1996).
%
%    See Vanhatalo and Vehtari (2007) and Vanhatalo et.al. (2010) for
%    more detailed discussion.
%
%    This demo is organised in three parts:
%     1) data analysis with Laplace approximation
%     2) data analysis with integrated Laplace approximation
%     3) data analysis with MCMC
%
%    See also  DEMO_REGRESSION1, DEMO_CLASSIFIC1
%
%
%   Refernces:
%    Vanhatalo, J., Pietiläinen V. and Vehtari, A. (2010). Approximate
%    inference for disease mapping with sparse Gaussian processes.
%    Statistics in Medicine, 29(15):.
%
%    Jarno Vanhatalo and Aki Vehtari (2007). Sparse Log Gaussian
%    Processes via MCMC for Spatial Epidemiology. JMLR Workshop and
%    Conference Proceedings, 1:73-89. (Gaussian Processes in Practice)

% Copyright (c) 2008-2010 Jarno Vanhatalo

% This software is distributed under the GNU General Public 
% License (version 2 or later); please refer to the file 
% License.txt, included with the software, for details.


% =====================================
% 1) Laplace approximation
% =====================================

% load the data
S = which('demo_spatial1');
data = load(strrep(S,'demo_spatial1.m','demos/spatial1.txt'));

xx = data(:,1:2);
ye = data(:,3);
yy = data(:,4);


% Now we have loaded the following parameters
% xx = co-ordinates 
% yy = number of deaths
% ye = the expexted number of deaths

% Set the inducing inputs in a regular grid.  Set_PIC returns the
% induving inputs and blockindeces for PIC. It also plots the data
% points, inducing inputs and blocks.
dims = [1    60     1    35];
[trindex, Xu] = set_PIC(xx, dims, 5, 'corners', 0);

[n,nin] = size(xx);

% Create the covariance functions
gpcf1 = gpcf_matern32('init', 'lengthScale', 5, 'magnSigma2', 0.05);
pl = prior_t('init');
pm = prior_t('init', 's2', 0.3);
gpcf1 = gpcf_matern32('set', gpcf1, 'lengthScale_prior', pl, 'magnSigma2_prior', pm);

% Create the likelihood structure
likelih = likelih_poisson('init');

% Create the FIC GP data structure so that inducing inputs are not optimized
gp = gp_init('init', 'FIC', likelih, {gpcf1}, [], 'X_u', Xu, 'jitterSigma2', 0.001);
gp = gp_init('set', gp, 'infer_params', 'covariance');

% REPLACE_WITH_DASH_DASH- MAP estimate with Laplace approximation REPLACE_WITH_DASH_DASH-

% Set the approximate inference method to Laplace approximation
gp = gp_init('set', gp, 'latent_method', {'Laplace', xx, yy, 'z', ye});

w=gp_pak(gp);  % pack the hyperparameters into one vector
fe=str2fun('gpla_e');     % create a function handle to negative log posterior
fg=str2fun('gpla_g');     % create a function handle to gradient of negative log posterior

% set the options for scg2
opt = scg2_opt;
opt.tolfun = 1e-3;
opt.tolx = 1e-3;
opt.display = 1;

% do the optimization and set the optimized hyperparameter values back to the gp structure
w=scg2(fe, w, opt, fg, gp, xx, yy, 'z', ye);
gp=gp_unpak(gp,w);

% make prediction to the data points
[Ef, Varf] = la_pred(gp, xx, yy, xx, 'z', ye, 'tstind', [1:n]);

% Define help parameters for plotting
xxii=sub2ind([60 35],xx(:,2),xx(:,1));
[X1,X2]=meshgrid(1:35,1:60);

% Plot the figures
% In the results it should be noticed that:
% - there is much more people living in the south than in the north. 
%   This results in rather high variance in the north
% - The eastern Finland is known to be worse than western Finland in 
%   heart diseases also from other studies.
% - The inducing inputs are set slightly too sparsely for this data, 
%   which results in oversmoothness in the maps
figure
G=repmat(NaN,size(X1));
G(xxii)=exp(Ef);
pcolor(X1,X2,G),shading flat
colormap(mapcolor(G)),colorbar
%set(gca, 'Clim', [0.6    1.5])
axis equal
axis([0 35 0 60])
title('Posterior mean of the relative risk, FIC')
printPmtkFigure('gpSpatialDemoLaplaceMean')


figure
G=repmat(NaN,size(X1));
G(xxii)=(exp(Varf) - 1).*exp(2*Ef+Varf);
pcolor(X1,X2,G),shading flat
colormap(mapcolor(G)),colorbar
%set(gca, 'Clim', [0.005    0.03])
axis equal
axis([0 35 0 60])
title('Posterior variance of the relative risk, FIC')
printPmtkFigure('gpSpatialDemoLaplaceVar')



% the MAP estimate of the hyperparameters in kilometers. Notice that the 
% co-ordinates in the data are not in kilometers. x=1 corresponds to 20km 
% in real life
S2 = sprintf('lengt-scale: %.3f, magnSigma2: %.3f \n', gp.cf{1}.lengthScale, gp.cf{1}.magnSigma2)

%{
% REPLACE_WITH_DASH_DASH- MCMC REPLACE_WITH_DASH_DASH-

% Set the approximate inference method to MCMC
gp = gp_init('set', gp, 'latent_method', {'MCMC', zeros(size(yy))', @scaled_hmc});

% Set the sampling options

% HMC-hyper
hmc_opt.steps=3;
hmc_opt.stepadj=0.01;
hmc_opt.nsamples=1;
hmc_opt.persistence=0;
hmc_opt.decay=0.8;
    
% HMC-latent
latent_opt.nsamples=1;
latent_opt.nomit=0;
latent_opt.persistence=0;
latent_opt.repeat=20;
latent_opt.steps=20;
latent_opt.stepadj=0.15;
latent_opt.window=5;

% Here we make an initialization with 
% slow sampling parameters
[rgp,gp,opt]=gp_mc(gp, xx, yy, 'z', ye, 'hmc_opt', hmc_opt, 'latent_opt', latent_opt);

% Now we reset the sampling parameters to 
% achieve faster sampling
opt.latent_opt.repeat=1;
opt.latent_opt.steps=7;
opt.latent_opt.window=1;
opt.latent_opt.stepadj=0.15;
opt.hmc_opt.persistence=0;
opt.hmc_opt.stepadj=0.01;
opt.hmc_opt.steps=2;

opt.display = 1;
opt.hmc_opt.display = 0;
opt.latent_opt.display=0;

% Define help parameters for plotting
xxii=sub2ind([60 35],xx(:,2),xx(:,1));
[X1,X2]=meshgrid(1:35,1:60);

% Conduct the actual sampling.
% Inside the loop we sample one sample from the latent values and 
% hyper-parameters at each iteration. After that we plot the samples 
% so that we can visually inspect the progress of sampling
while length(rgp.edata)<1000 %   1000
    [rgp,gp,opt]=gp_mc(gp, xx, yy, 'record', rgp, 'z', ye, opt);
    fprintf('        mean hmcrej: %.2f latrej: %.2f\n', mean(rgp.hmcrejects), mean(rgp.lrejects))
    figure(3)
    clf
    subplot(1,2,1)
    plot(rgp.cf{1}.lengthScale, rgp.cf{1}.magnSigma2)
    xlabel('lenght-scale')
    ylabel('magnitude')
    hold on
    plot(rgp.cf{1}.lengthScale(end), rgp.cf{1}.magnSigma2(end),'r*')
    drawnow
    %    subplot(2,2,[2 4])
    subplot(1,2,2)
    G=repmat(NaN,size(X1));
    G(xxii)=exp(gp.latentValues);
    pcolor(X1,X2,G),shading flat
    colormap(mapcolor(G)),colorbar
    axis equal
    axis([0 35 0 60])
    title('relative risk')
    drawnow
end

figure(3)
clf
G=repmat(NaN,size(X1));
G(xxii)=median(exp(rgp.latentValues));
pcolor(X1,X2,G),shading flat
colormap(mapcolor(G)),colorbar
set(gca, 'Clim', [0.6    1.5])
axis equal
axis([0 35 0 60])
title('Posterior median of relative risk, FIC GP')

figure(4)
G=repmat(NaN,size(X1));
G(xxii)=std(exp(rgp.latentValues), [], 1).^2;
pcolor(X1,X2,G),shading flat
colormap(mapcolor(G)),colorbar
set(gca, 'Clim', [0.005    0.03])
axis equal
axis([0 35 0 60])
title('Posterior variance of relative risk, FIC GP')
%}


##### SOURCE END #####
--></body></html>