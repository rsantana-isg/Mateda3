
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Bayesian infernece for simple linear regression with known noise variance</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-03-27"><meta name="DC.source" content="bayesLinRegDemo2d.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Bayesian infernece for simple linear regression with known noise variance</h1><!--introduction--><p>The goal is to reproduce fig 3.7 from Bishop's book We fit the linear model f(x,w) = w0 + w1 x and plot the posterior over w.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#3">Generate the training points</a></li><li><a href="#4">Plot</a></li></ul></div><pre class="codeinput"><span class="comment">% This file is from pmtk3.googlecode.com</span>

<span class="keyword">function</span> bayesLinRegDemo2d()
</pre><pre class="codeinput">setSeed(1); <span class="comment">% seed 0 reproduces Bishop's figure</span>
a0 = -0.3; <span class="comment">%Parameters of the actual underlying model that we wish to recover</span>
a1 = 0.5;  <span class="comment">%We will estimate these values with w0 and w1 respectively.</span>

trainingPoints = 20;    <span class="comment">% Number of (x,y) training points</span>
noiseSD = 0.2;          <span class="comment">% Standard deviation of Gaussian noise, applied to actual underlying model.</span>
priorPrecision = 2.0;   <span class="comment">% Fix the prior precision, alpha. We will use a zero-mean isotropic Gaussian.</span>
likelihoodSD = noiseSD; <span class="comment">% Assume the likelihood precision, beta, is known.</span>
likelihoodPrecision = 1/(likelihoodSD)^2;
</pre><h2>Generate the training points<a name="3"></a></h2><pre class="codeinput">xtrain = -1 + 2*rand(trainingPoints,1);
model = struct(<span class="string">'mu'</span>, 0, <span class="string">'Sigma'</span>, noiseSD);
noise = gaussSample(model, trainingPoints);
ytrain = a0 + a1*xtrain + noise;
</pre><h2>Plot<a name="4"></a></h2><p>Number of successive data points for which likelihood distributions will be graphed. The prior and the last data point are always plotted so 0 &lt;= iter &lt;= trainingPoints - 1.</p><pre class="codeinput">iter = 2;
<span class="comment">% Plot the prior distribution over w0, w1</span>
subplot2(iter+2,3,1,2);
priorMean = [0;0];
priorSigma = eye(2)./priorPrecision; <span class="comment">%Covariance Matrix</span>
priorPDF = @(W)gaussProb(W,priorMean',priorSigma);
contourPlot(priorPDF,[]);
<span class="comment">% Plot sample lines whose parameters are drawn from the prior distribution.</span>
subplot2(iter+2,3,1,3);
plotSampleLines(priorMean',priorSigma,6,[])

<span class="comment">% For each iteration plot the likelihood of the ith data point, the</span>
<span class="comment">% posterior over the first i data points and sample lines whose</span>
<span class="comment">% parameters are drawn from the corresponding posterior.</span>
mu = priorMean;
sigma = priorSigma;
<span class="keyword">for</span> i=1:iter
  subplot2(2+iter,3,i+1,1);
  likelihood = @(W) uniGaussPdf(xtrain(i),W*[1;xtrain(i)],likelihoodSD.^2);
  contourPlot(likelihood,[a0,a1]);

  subplot2(2+iter,3,i+1,2);
  [postW,mu,sigma] = update([1,xtrain(i)],ytrain(i),likelihoodPrecision,mu,sigma);
  contourPlot(postW,[a0,a1]);

  subplot2(2+iter,3,i+1,3);
  plotSampleLines(mu,sigma,6,[xtrain(1:i),ytrain(1:i)]);
<span class="keyword">end</span>
<span class="comment">% Plot likelihood for the last point alone</span>
last = trainingPoints;
subplot2(2+iter,3,iter+2,1);
likelyhoodLast = @(W) uniGaussPdf(xtrain(last),W*[1;xtrain(last)],likelihoodSD.^2);
contourPlot(likelyhoodLast,[a0,a1]);
<span class="comment">% Plot the posterior over all of the training data.</span>
subplot2(2+iter,3,iter+2,2);
[postW,mu,sigma] = update([ones(trainingPoints,1),xtrain],ytrain,likelihoodPrecision,priorMean,priorSigma);
contourPlot(postW,[a0,a1]);
<span class="comment">% Plot sample lines whose parameters are drawn from the posterior.</span>
subplot2(2+iter,3,iter+2,3);
plotSampleLines(mu',sigma,6,[xtrain,ytrain]);

<span class="comment">% Add titles</span>
subplot2(2+iter,3,1,1);
title(<span class="string">'likelihood'</span>);
axis <span class="string">off</span>;
subplot2(2+iter,3,1,2);
title(<span class="string">'prior/posterior'</span>);
subplot2(2+iter,3,1,3);
title(<span class="string">'data space'</span>);


printPmtkFigure <span class="string">bayesLinRegPlot2dB</span>
</pre><img vspace="5" hspace="5" src="bayesLinRegDemo2d_01.png" alt=""> <pre class="codeinput"><span class="keyword">end</span>

<span class="keyword">function</span> plotSampleLines(mu, sigma, numberOfLines,dataPoints)
<span class="comment">% Plot the specified number of lines of the form y = w0 + w1*x in [-1,1]x[-1,1] by</span>
<span class="comment">% drawing w0, w1 from a bivariate normal distribution with specified values</span>
<span class="comment">% for mu = mean and sigma = covariance Matrix. Also plot the data points as</span>
<span class="comment">% blue circles.</span>
<span class="keyword">for</span> i = 1:numberOfLines
    model = struct(<span class="string">'mu'</span>, mu, <span class="string">'Sigma'</span>, sigma);
    w = gaussSample(model);
    func = @(x) w(1) + w(2)*x;
    fplot(func,[-1,1,-1,1],<span class="string">'r'</span>);
    hold <span class="string">on</span>;
<span class="keyword">end</span>
axis <span class="string">square</span>;
set(gca,<span class="string">'XTick'</span>,[-1,0,1]);
set(gca,<span class="string">'YTick'</span>,[-1,0,1]);
xlabel(<span class="string">' x '</span>);
ylabel(<span class="string">' y '</span>,<span class="string">'Rotation'</span>,0);
<span class="keyword">if</span>(size(dataPoints,2) == 2)
    hold <span class="string">on</span>;
    plot(dataPoints(:,1),dataPoints(:,2),<span class="string">'ob'</span>);
<span class="keyword">end</span>


<span class="comment">%Generates a colour filled contour plot of the bivariate function, 'func'</span>
<span class="comment">%over the domain [-1,1]x[-1,1], plotting it to the current figure. Also plots</span>
<span class="comment">%the specified point as a white cross.</span>
<span class="keyword">end</span>
<span class="keyword">function</span> contourPlot(func,trueValue)
stepSize = 0.05;
[x,y] = meshgrid(-1:stepSize:1,-1:stepSize:1); <span class="comment">% Create grid.</span>
[r,c]=size(x);

data = [x(:) y(:)];
p = func(data);
p = reshape(p, r, c);

contourf(x,y,p,256,<span class="string">'LineColor'</span>,<span class="string">'none'</span>);
colormap(jet(256));
axis <span class="string">square</span>;
set(gca,<span class="string">'XTick'</span>,[-1,0,1]);
set(gca,<span class="string">'YTick'</span>,[-1,0,1]);
xlabel(<span class="string">' W0 '</span>);
ylabel(<span class="string">' W1 '</span>,<span class="string">'Rotation'</span>,0);
<span class="keyword">if</span>(length(trueValue) == 2)
    hold <span class="string">on</span>;
    plot(trueValue(1),trueValue(2),<span class="string">'+w'</span>);
<span class="keyword">end</span>
<span class="keyword">end</span>
<span class="comment">%</span>
<span class="comment">% Given the mean = priorMu and covarianceMatrix = priorSigma of a prior</span>
<span class="comment">% Gaussian distribution over regression parameters; observed data, xtrain</span>
<span class="comment">% and ytrain; and the likelihood precision, generate the posterior</span>
<span class="comment">% distribution, postW via Bayesian updating and return the updated values</span>
<span class="comment">% for mu and sigma. xtrain is a design matrix whose first column is the all</span>
<span class="comment">% ones vector.</span>
<span class="keyword">function</span> [postW,postMu,postSigma] = update(xtrain,ytrain,likelihoodPrecision,priorMu,priorSigma)

postSigma  = inv(inv(priorSigma) + likelihoodPrecision*xtrain'*xtrain);
postMu = postSigma*inv(priorSigma)*priorMu + likelihoodPrecision*postSigma*xtrain'*ytrain;
postW = @(W)gaussProb(W,postMu',postSigma);

<span class="keyword">end</span>
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
%% Bayesian infernece for simple linear regression with known noise variance
% The goal is to reproduce fig 3.7 from Bishop's book
% We fit the linear model f(x,w) = w0 + w1 x and plot the posterior over w.
%%

% This file is from pmtk3.googlecode.com

function bayesLinRegDemo2d()
setSeed(1); % seed 0 reproduces Bishop's figure
a0 = -0.3; %Parameters of the actual underlying model that we wish to recover
a1 = 0.5;  %We will estimate these values with w0 and w1 respectively. 

trainingPoints = 20;    % Number of (x,y) training points
noiseSD = 0.2;          % Standard deviation of Gaussian noise, applied to actual underlying model. 
priorPrecision = 2.0;   % Fix the prior precision, alpha. We will use a zero-mean isotropic Gaussian.
likelihoodSD = noiseSD; % Assume the likelihood precision, beta, is known.
likelihoodPrecision = 1/(likelihoodSD)^2; 
%% Generate the training points
xtrain = -1 + 2*rand(trainingPoints,1);
model = struct('mu', 0, 'Sigma', noiseSD);
noise = gaussSample(model, trainingPoints);
ytrain = a0 + a1*xtrain + noise;
%% Plot
% Number of successive data points for which likelihood distributions will
% be graphed. The prior and the last data point are always plotted so 0 <=
% iter <= trainingPoints - 1.
iter = 2; 
% Plot the prior distribution over w0, w1
subplot2(iter+2,3,1,2);
priorMean = [0;0];
priorSigma = eye(2)./priorPrecision; %Covariance Matrix
priorPDF = @(W)gaussProb(W,priorMean',priorSigma);
contourPlot(priorPDF,[]);
% Plot sample lines whose parameters are drawn from the prior distribution.
subplot2(iter+2,3,1,3);
plotSampleLines(priorMean',priorSigma,6,[])

% For each iteration plot the likelihood of the ith data point, the
% posterior over the first i data points and sample lines whose
% parameters are drawn from the corresponding posterior. 
mu = priorMean;
sigma = priorSigma;
for i=1:iter
  subplot2(2+iter,3,i+1,1);
  likelihood = @(W) uniGaussPdf(xtrain(i),W*[1;xtrain(i)],likelihoodSD.^2);
  contourPlot(likelihood,[a0,a1]);
  
  subplot2(2+iter,3,i+1,2);
  [postW,mu,sigma] = update([1,xtrain(i)],ytrain(i),likelihoodPrecision,mu,sigma);
  contourPlot(postW,[a0,a1]);
  
  subplot2(2+iter,3,i+1,3);
  plotSampleLines(mu,sigma,6,[xtrain(1:i),ytrain(1:i)]);  
end
% Plot likelihood for the last point alone
last = trainingPoints;
subplot2(2+iter,3,iter+2,1);
likelyhoodLast = @(W) uniGaussPdf(xtrain(last),W*[1;xtrain(last)],likelihoodSD.^2);
contourPlot(likelyhoodLast,[a0,a1]);
% Plot the posterior over all of the training data. 
subplot2(2+iter,3,iter+2,2);
[postW,mu,sigma] = update([ones(trainingPoints,1),xtrain],ytrain,likelihoodPrecision,priorMean,priorSigma);
contourPlot(postW,[a0,a1]);
% Plot sample lines whose parameters are drawn from the posterior. 
subplot2(2+iter,3,iter+2,3);
plotSampleLines(mu',sigma,6,[xtrain,ytrain]);

% Add titles
subplot2(2+iter,3,1,1);
title('likelihood');
axis off;
subplot2(2+iter,3,1,2);
title('prior/posterior');
subplot2(2+iter,3,1,3);
title('data space');


printPmtkFigure bayesLinRegPlot2dB
end

function plotSampleLines(mu, sigma, numberOfLines,dataPoints)
% Plot the specified number of lines of the form y = w0 + w1*x in [-1,1]x[-1,1] by
% drawing w0, w1 from a bivariate normal distribution with specified values
% for mu = mean and sigma = covariance Matrix. Also plot the data points as
% blue circles. 
for i = 1:numberOfLines
    model = struct('mu', mu, 'Sigma', sigma);
    w = gaussSample(model);
    func = @(x) w(1) + w(2)*x;
    fplot(func,[-1,1,-1,1],'r');
    hold on;
end
axis square;
set(gca,'XTick',[-1,0,1]);
set(gca,'YTick',[-1,0,1]);
xlabel(' x ');
ylabel(' y ','Rotation',0);
if(size(dataPoints,2) == 2)
    hold on;
    plot(dataPoints(:,1),dataPoints(:,2),'ob');    
end


%Generates a colour filled contour plot of the bivariate function, 'func'
%over the domain [-1,1]x[-1,1], plotting it to the current figure. Also plots
%the specified point as a white cross. 
end
function contourPlot(func,trueValue)
stepSize = 0.05; 
[x,y] = meshgrid(-1:stepSize:1,-1:stepSize:1); % Create grid.
[r,c]=size(x);

data = [x(:) y(:)];
p = func(data);
p = reshape(p, r, c);
 
contourf(x,y,p,256,'LineColor','none');
colormap(jet(256));
axis square;
set(gca,'XTick',[-1,0,1]);
set(gca,'YTick',[-1,0,1]);
xlabel(' W0 ');
ylabel(' W1 ','Rotation',0);
if(length(trueValue) == 2)
    hold on;
    plot(trueValue(1),trueValue(2),'+w');
end
end
%
% Given the mean = priorMu and covarianceMatrix = priorSigma of a prior
% Gaussian distribution over regression parameters; observed data, xtrain
% and ytrain; and the likelihood precision, generate the posterior
% distribution, postW via Bayesian updating and return the updated values
% for mu and sigma. xtrain is a design matrix whose first column is the all
% ones vector.
function [postW,postMu,postSigma] = update(xtrain,ytrain,likelihoodPrecision,priorMu,priorSigma)

postSigma  = inv(inv(priorSigma) + likelihoodPrecision*xtrain'*xtrain); 
postMu = postSigma*inv(priorSigma)*priorMu + likelihoodPrecision*postSigma*xtrain'*ytrain; 
postW = @(W)gaussProb(W,postMu',postSigma);

end

##### SOURCE END #####
--></body></html>