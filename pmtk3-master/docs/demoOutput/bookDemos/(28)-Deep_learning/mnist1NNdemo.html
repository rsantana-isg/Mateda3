
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Classify the MNIST digits using a one nearest neighbour classifier and Euclidean distance</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2012-03-27"><meta name="DC.source" content="mnist1NNdemo.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Classify the MNIST digits using a one nearest neighbour classifier and Euclidean distance</h1><!--introduction--><p>See mnistKNNdeno for a simple minded implemenation. This demo uses various tricks to scale the method up to large data sets.</p><!--/introduction--><p>PMTKslow</p><pre class="codeinput"><span class="comment">% This file is from pmtk3.googlecode.com</span>

loadData(<span class="string">'mnistAll'</span>);
<span class="keyword">if</span> 0
  <span class="comment">% test on all data- 255 seconds, 3.09% error</span>
  trainndx = 1:60000; testndx =  1:10000;
<span class="keyword">else</span>
   <span class="comment">% train on 10k, test on 1k - 1.39 seconds, 8.00% error</span>
  <span class="comment">% train on 60k, test on 1k - 8 seconds, 3.80% error</span>
  trainndx = 1:60000;
  testndx =  1:1000;
<span class="keyword">end</span>
ntrain = length(trainndx);
ntest = length(testndx);
Xtrain = double(reshape(mnist.train_images(:,:,trainndx),28*28,ntrain)');
Xtest  = double(reshape(mnist.test_images(:,:,testndx),28*28,ntest)');

<span class="keyword">if</span> 0
  <span class="comment">% matrix is real-valued but has many zeros due to black boundary</span>
  <span class="comment">% so we make it sparse to save space - does not work in octave</span>
  Xtrain = sparse(Xtrain);
  Xtest = sparse(Xtest);
<span class="keyword">end</span>

ytrain = (mnist.train_labels(trainndx));
ytest  = (mnist.test_labels(testndx));
clear <span class="string">mnist</span> <span class="string">trainndx</span> <span class="string">testndx</span>; <span class="comment">% save space</span>

tic
<span class="comment">% Precompute sum of squares term for speed</span>
XtrainSOS = sum(Xtrain.^2,2);
XtestSOS  = sum(Xtest.^2,2);

<span class="comment">% fully vectorized solution takes too much memory so we will classify in batches</span>
<span class="comment">% nbatches must be an even divisor of ntest, increase if you run out of memory</span>
<span class="keyword">if</span> ntest &gt; 1000
  nbatches = 50;
  <span class="keyword">else</span>
  nbatches = 5;
<span class="keyword">end</span>
batches = mat2cell(1:ntest,1,(ntest/nbatches)*ones(1,nbatches));
ypred = zeros(ntest,1);
<span class="keyword">if</span> ~isOctave(), wbar = waitbar(0,sprintf(<span class="string">'%d of %d classified'</span>,0,ntest)); <span class="keyword">end</span> <span class="comment">% waitbar only works in Matlab</span>
<span class="comment">% Classify</span>
<span class="keyword">for</span> i=1:nbatches
    t = toc; <span class="keyword">if</span> ~isOctave(), waitbar(i/nbatches,wbar,sprintf(<span class="string">'%d of %d Classified\nElapsed Time: %.2f seconds'</span>,(i-1)*(ntest/nbatches),ntest,t));<span class="keyword">end</span>
    dst = sqDistance(Xtest(batches{i},:),Xtrain,XtestSOS(batches{i},:),XtrainSOS);
    [junk,closest] = min(dst,[],2);
    ypred(batches{i}) = ytrain(closest);
<span class="keyword">end</span>
<span class="comment">% Report</span>
<span class="keyword">if</span> ~isOctave(), close(wbar); <span class="keyword">end</span>
errorRate = mean(ypred ~= ytest);
fprintf(<span class="string">'Error Rate: %.2f%%\n'</span>,100*errorRate);
t = toc; fprintf(<span class="string">'Total Time: %.2f seconds\n'</span>,t);
</pre><pre class="codeoutput">Error Rate: 3.80%
Total Time: 10.10 seconds
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
%% Classify the MNIST digits using a one nearest neighbour classifier and Euclidean distance
% See mnistKNNdeno for a simple minded implemenation.
% This demo uses various tricks to scale the method up to large
% data sets.
%%
% PMTKslow
%%

% This file is from pmtk3.googlecode.com

loadData('mnistAll');
if 0
  % test on all data- 255 seconds, 3.09% error
  trainndx = 1:60000; testndx =  1:10000;
else
   % train on 10k, test on 1k - 1.39 seconds, 8.00% error
  % train on 60k, test on 1k - 8 seconds, 3.80% error
  trainndx = 1:60000; 
  testndx =  1:1000; 
end
ntrain = length(trainndx);
ntest = length(testndx);
Xtrain = double(reshape(mnist.train_images(:,:,trainndx),28*28,ntrain)');
Xtest  = double(reshape(mnist.test_images(:,:,testndx),28*28,ntest)');

if 0 
  % matrix is real-valued but has many zeros due to black boundary
  % so we make it sparse to save space - does not work in octave
  Xtrain = sparse(Xtrain);
  Xtest = sparse(Xtest);
end

ytrain = (mnist.train_labels(trainndx));
ytest  = (mnist.test_labels(testndx));
clear mnist trainndx testndx; % save space

tic
% Precompute sum of squares term for speed
XtrainSOS = sum(Xtrain.^2,2);
XtestSOS  = sum(Xtest.^2,2);

% fully vectorized solution takes too much memory so we will classify in batches
% nbatches must be an even divisor of ntest, increase if you run out of memory 
if ntest > 1000
  nbatches = 50;
  else
  nbatches = 5;
end
batches = mat2cell(1:ntest,1,(ntest/nbatches)*ones(1,nbatches));
ypred = zeros(ntest,1);
if ~isOctave(), wbar = waitbar(0,sprintf('%d of %d classified',0,ntest)); end % waitbar only works in Matlab
% Classify
for i=1:nbatches
    t = toc; if ~isOctave(), waitbar(i/nbatches,wbar,sprintf('%d of %d Classified\nElapsed Time: %.2f seconds',(i-1)*(ntest/nbatches),ntest,t));end
    dst = sqDistance(Xtest(batches{i},:),Xtrain,XtestSOS(batches{i},:),XtrainSOS);
    [junk,closest] = min(dst,[],2);
    ypred(batches{i}) = ytrain(closest);
end
% Report
if ~isOctave(), close(wbar); end
errorRate = mean(ypred ~= ytest);
fprintf('Error Rate: %.2f%%\n',100*errorRate);
t = toc; fprintf('Total Time: %.2f seconds\n',t);

##### SOURCE END #####
--></body></html>